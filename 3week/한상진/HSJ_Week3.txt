# 처리율 제한 장치

- 클라이언트, 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치.
- 임계치(threshold)를 넘어선 뒤 추가로 도달하는 호출은 처리가 중단됨

# 처리율 제한 장치 사용 이유

1. DoS(Denial of Service) 공격에 의한 자원 고갈(Resource Starvation)을 방지
    - 추가쵸청에 대한 처리를 중단해 DoS 공격을 방지함.
2. 비용 절감
    - 처리를 제한해 서버를 많이 두지 않아도 됌.
3. 서버 과부하를 막는다.

# 4단계 접근 방법 적용

## 1. 문제 이해 및 설계 범위 확정

- 면접관과의 대화를 통해 문제 이해 및 처리율 제한 장치의 설계범위 확정
    - ex) 클라이언트 측 제한 장치인지 서버 측 제한 장치인지, 규모, 호출 제어 기준 등등…

## 2. 개략적 설계안 제시 및 동의 구하기

### 처리율 장치의 위치 설정

- 클라이언트 측
    - 위변조가 가능하여 권장하지 않는다.
- 서버 측
    - 중앙화해서 관리한다.
- 처리율 제한 미들웨어
    - 클라우드 마이크로서비스의 경우 처리율 제한 장치는 보통 API Gateway에 구현.
        - API Gateway: 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁 관리형 서비스.

### 처리율 제한 알고리즘 설정

- 토큰 버킷 알고리즘
    - 버킷에 토큰이 주기적으로 채워진다.
    - 각 요청이 처리될 때마다 하나의 토큰을 사용한다.
    - 토큰이 없다면 해당 요청은 버려진다.
- 누출 버킷 알고리즘
    - 요청이 들어오면 큐가 가득 차 있는지 체크.
        - 빈 자리가 있다면 큐에 요청을 추가한다.
        - 만약 큐가 가득 차 있다면 요청은 버린다.
    - 지정된 시간마다 큐에서 요청을 꺼내어 처리.
- 고정 윈도 카운터 알고리즘, 이동 윈도 로깅 알고리즘 등이 존재
- 처리율 제한 알고리즘은 결국 추적 Target 별 요청의 수를 통해 응답할지 거부할지 결정.

## 3. 상세 설계

### 처리율 제한 규칙

- 처리율 제한 규칙들은 설정 파일 형태로 디스크에 저장
    

### 처리율 한도 초과 트래픽의 처리

- HTTP 429 응답(Too many requests)을 Clinet에게 보냄.
- 경우에 따라 한도 제한이 걸린 메시지를 나중 처리를 위해 큐에 보관

### 단일 서버에서의 상세 설계

- 처리율 제한 규칙은 디스크에 저장하고 작업 프로세스가 수시로 디스크에서 읽어서 캐시에 저장.
- 클라이언트가 요청을 보내면 처리율 제한 미들웨어에 도착.
- 처리율 제한 미들웨어는 캐시에서 규칙을 가져오고 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온 뒤, 가져온 값에 근거하여 결정을 내린다.
    - 해당 요청이 처리율 제한에 걸리지 않으면 API서버로 보냄.
    - 처리율 제한에 걸리면 Http Status는 429를 보냄. 요청은 폐기하거나 큐에 보관.

### 분산 환경에서의 처리율 제한 장치의 구현

- 단일 서버에서 여러 대의 서버를 이용하려면 2가지 문제를 해결해야함.

**(1) 경쟁 조건**

- Counter의 값을 2개의 서버에서 동시에 증가시켜 counter의 값이 1만 증가할 수 있음
    → (실제로는 2 증가해야하는데)
    
- 해결법
    - 1) Lock 이용
        - 락(lock)을 걸 수도 있지만 성능이 떨어진다는 문제가 있다.
    - 2) 레디스 자료구조 이용
        - 루아 스크립트(Lua script)나 정렬 집합(sorted set)이라 불리는 **레디스 자료구조를 사용**하여 해결할 수 있다.

**(2) 동기화 이슈**

- 많은 사용자를 지원하기 위해 처리율 제한 장치 서버를 여러 대 두게 되면, 동기화가 필요
    - 웹 계층은 stateless하므로 clinet의 다음 요청이 이전 장치와 다른 장치에 갈 수 있기 때문.
- 해결법
    - 1) 고정 세션을 활용
        - 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있지만 유연하지 않음.
    - 2) 레디스와 같은 중앙 집중형 데이터 저장소 이용

### 성능 최적화

- 여러 데이터 센터를 지원해야한다.
    - 사용자와의 거리가 멀어질수록 지연시간이 증가하기 때문
- 제한 장치 간 데이터 동기화에 최종 일관성 모델을 사용 (이게 뭔데?)

### 모니터링

- 처리율 제한 장치가 효과적으로 동작하는지 보기 위한 메트릭을 수집

## 마무리

- 다른 부분들을 추가적으로 생각해보는 시간

# 도입

- 수평정 규모 확정성을 달성하기 위해서는 **요청이나 데이터를 서버에 균등**하게 나누는 것이 중요.

# 해시 키 재배치 문제

- 해시 함수를 이용해 서버들에 부하를 균등하게 분배.
- 이 방법은 서버가 추가되거나 삭제 되는 경우 대규모 캐시 미스 문제를 발생시킴.

# 안정 해시

- 해시 테이블의 크기가 조정될 때 평균적으로 k/n개의 키만 재배치하는 해시 기술이다.
    
    (k = 키의 개수, n = 슬롯 개수)
    
## 동작 원리

- 해시 공간의 시작과 끝을 이어서 링을 만든 후, 해시 공간 위에 해시 서버들을 배치
- 해시 함수를 통과한 값은 시계 방향으로 링을 탐색 → 만나는 첫번째 서버에 저장됨.

## 안정 해시 구현법의 두 가지 문제

### 1. 파티션의 크기를 균등하게 유지하는 게 불가능.

- 어떤 서버는 굉장힉 작은 해시 공간을 , 어떤 서버는 굉장히 큰 해시 공간을 할당 받을 수 있음.
    - EX) 처음에는 균등했어도, 어느 서버 하나가 죽어버리면 뒤의 서버는 남들의 2배 만큼의 해시 공간을 할당 받음

### 2.키의 균등 분포를 달성하기가 어렵다.

# 가상 노드

- 실제 노드 또는 서버를 가리키는 노드, 하나의 서버는 여러 개의 가상 노드를 가질 수 있음.
- 해시 공간에 배치된 노드 수가 굉장히 많다면 표준편차가 감소하여 노드 하나가 없어진다 하더라도 다음 노드에 큰 부하는 가지 않을 것이라는 아이디어!
- 단점
    - 가상 노드의 수를 늘리면 가상 노드 데이터를 저장할 공간이 더 많이 필요. ← 타협이 필요!
